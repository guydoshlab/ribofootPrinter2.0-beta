from Bio import SeqIO
from Bio import Seq
import csv
import os
import pandas as pd
import numpy as np
import sys

# This is the 3D metagene function. 
# It outputs 2 csv files of 3D metagenes - one for 5' mapped reads and one for 3' mapped reads. It also outputs a matching 1D metagene csv with 5' and 3' mappings.
# Plotting the 3D metagenes is done with a separate function.
# Inputs:
# fasta_in - This is the longnames fasta file.
# sam_in - This is the SAM input file of your mapped reads.
# outfile - root name that will be used for multiple output files (no csv extension)
# subset_list - filter list file (e.g. subset_list.xlsx), if no filtering is required put "none". These are the only genes included if provided.
# smallsize - min footprint size, inclusive
# largesize - max footprint size, inclusive
# window_left- window size of upstream region of start or stop codon.
# window_right - window size of downstream region of start or stop codon.
# metagene options: put 1 for start or 2 for stop.
# Note that this metagene performs the arithmetic mean of all reads that map to particular positions; it does not calculate a normalized average where every gene has equal representation.
def main(fasta_in,sam_in,outfile_path,subset_list,smallsize,largesize,window_left,window_right,metagene):
	print("\nName of python script:",(__file__.split("/")[-1]))
	print("Total arguments passed:", len(locals()))
	print("Argument names: "+("; ".join(list(locals().keys()))))
	argkeys=list(locals().keys())
	argvals=[]
	for key in argkeys:
		argvals.append((locals()[key]))
	print("Argument values: "+("; ".join(argvals)))   

	smallsize=int(smallsize)
	largesize=int(largesize)
	window_left=int(window_left)
	window_right=int(window_right)
	metagene=int(metagene)

	gene_list = None
	if subset_list != "none":
		selection = pd.read_excel(subset_list) # Provide list of genenames to subset dataset
		gene_list = set(selection["genename"].tolist())
		print ("Subset list was loaded containing " + str(len(gene_list)) + " genes.")

	genedata={}		# Creates an empty dictionary for looking up gene information.
	UTRshort=[]		# Empty list for storing gene names that have a UTR too short for this analysis. 
	totalgenes=0	# Counter for all genes in the fasta.
	genecounter=0	# Counter for genes that are included in the analysis (total less those with a too short UTR)
    # Read in the fasta file with longnames to obtain all gene information
	for record in SeqIO.parse(fasta_in, "fasta"):       # Reading in a fasta file using the SeqIO package.
		totalgenes+=1
		gene=record.id.split("|")[0]                    # Obtains genename from fasta file (i.e. ENSG000000001.12).
		genedata[gene]=["alias","sequence",{},"ORFstart","utr3start","transcriptlen"] #  Generates a list with placeholders.
		#genedata[gene][0]=record.id.split("|")[5]	                    # Alias name of gene
		genedata[gene][1]=str(record.seq)	                            # Sequence of transcript
		genedata[gene][3]=(record.id.split("|")[7]).split("-")[-1]	# ORF start
		genedata[gene][4]=(record.id.split("|")[8]).split("-")[-1]	# UTR3 start
		
		# Check here for utr length vs window.
		stopcodon=int(genedata[gene][4])-3
		startcodon=int(genedata[gene][3])
		genelen=len(genedata[gene][1])
		
		if metagene==1:
			if (startcodon<window_left):
				UTRshort.append(gene)	# Create a dictionary of gene names with too short UTRs.
				continue
		elif metagene==2:
			if ((genelen-stopcodon+3)<window_right):
				UTRshort.append(gene)	# Create a dictionary of gene names with too short UTRs.
				continue
		
		if gene_list is not None and gene not in gene_list:  # Filter out any genes that are not in the subset list
			continue
	
		genecounter+=1	

	print("\nTotal genes in fasta file = "+str(totalgenes))
	print("Genes dropped due to a UTR shorter than a window = "+str(len(UTRshort)))	
	print("Genes used for analysis after dropping short UTRs and any non-subset = "+str(genecounter)+"\n")

	cols = window_left+window_right+1 # The start/stop codons is not counted in the window.
	rows = 101 # max. footprint size would be 100 nt
	if largesize>=rows:
		print("Desired largest readsize exceeds 100 nt. Not compatible.")
		exit()
	matrix = [[0 for x in range(cols)] for x in range(rows)]	# For 5' mappings
	matrix3 = [[0 for x in range(cols)] for x in range(rows)]	# For 3' mappings

    # Loop through the samfile.
	fsam=open(sam_in)           # Opening the SAM file generated by bowtie which contains information for each read aligned against the transcriptome.
	samgen=csv.reader(fsam,delimiter='	')  # Reading the tab-separated SAM file. The variable samgen is a list containing read alignment information.
	mappedreads=0
	counter = 0
	UTRshortreads=0
	finalreads5=0
	finalreads3=0

	for read in samgen:
		if read[0][0] == '@':   # Ignore header lines.
			continue
		if read[1] == '4':      # A bowtie no match. 
			continue
		if (read[1] == '16'):	# Remove negative strands
			continue

		gene = read[2]             # gene identified for read in bowtie. 
		startp = int(read[3]) - 1    # start position. Need to subtract 1 since genomic sequence starts at 1, but list structures for read summing start at 0.
		seq = Seq.Seq(read[9])      # sequence of the read
		length = len(seq)           # length of read
		endp = int(read[3])+int(length)-1	# end of read position.
		startcodon=int(genedata[gene][3])
		stopcodon=int(genedata[gene][4])-3
        
		if (length<smallsize or length>largesize):
			continue

		counter+=1
		if counter % 500000 == 0:
			print("Processed " + str(counter) + " reads...")
        
		if gene in UTRshort:
			UTRshortreads+=1
			continue

		if gene_list is not None and gene not in gene_list:  # Filter out any genes that are not in the subset list
			continue

		# Below a series of checks are made to see if the read is a match to the transcriptome, if it is in the subset list, if the gene's UTR is long enough to accomodate, and if the 5' and 3' ends of the reads fit in the window.
		# If all true, it is added into the average.
		# Start codons
		if (read[1] == '0') and metagene == 1:	    		# mapped reads that are going to be counted
			mappedreads+=1
			if (startp <= startcodon+window_right and startp >= startcodon-window_left):   # test if read 5' end falls within start or stop codon region
				startp_rel = (startp - startcodon) + window_left # substract startcodon from startp to align all transcripts within window 
				matrix[length][startp_rel]+=1
				finalreads5+=1
			if (endp <= startcodon+window_right and endp >= startcodon-window_left):   # test if read 3' end falls within start or stop codon region
				endp_rel = (endp - startcodon) + window_left # substract startcodon from startp to align all transcripts within window 
				matrix3[length][endp_rel]+=1
				finalreads3+=1
   
        # Stop codons
		if (read[1] == '0') and metagene == 2:	    		# mapped reads that are going to be counted
			mappedreads+=1
			if (startp <= stopcodon+window_right and startp >= stopcodon-window_left):   # test if read 5' end falls within start or stop codon region
				startp_rel = (startp - stopcodon) + window_left # substract stopcodon from startp to align all transcripts within window 
				matrix[length][startp_rel]+=1
				finalreads5+=1	
			if (endp <= stopcodon+window_right and endp >= stopcodon-window_left):   # test if read 3' end falls within start or stop codon region         
				endp_rel = (endp - stopcodon) + window_left # substract stopcodon from startp to align all transcripts within window 
				matrix3[length][endp_rel]+=1
				finalreads3+=1
	fsam.close()
	
	print("\nReads mapping to sense strand = "+str(counter))
	print("Reads dropped due to gene having a UTR shorter than a window = "+str(UTRshortreads))
	print("Reads dropped due to 5' end not being in window around start/stop codon = "+str(mappedreads-finalreads5))
	print("Reads dropped due to 3' end not being in window around start/stop codon = "+str(mappedreads-finalreads3))
	print("Total reads in 5' metagene = "+str(finalreads5))
	print("Total reads in 3' metagene = "+str(finalreads3))

	# Do normalizations
	if mappedreads == 0:
		print("Error: no genes expressed")
		exit()
	else:
		norm_number = 1E6/float(counter)	# First convert to rpm. Rpm includes all mapped reads, excluding those on the negative strand or outside the input size range.
		norm_number/=genecounter # Then divide by number of genes so it is a true meta-"gene". Excludes too short UTR and any non-subset genes.
    	
	matrix = np.array(matrix)        
	matrix = matrix * norm_number
	range_column = list(range(0, rows))
	outfile = matrix
	df = pd.DataFrame(outfile)
	df.columns = (list(range(-window_left,window_right+1)))
	df.insert(0, 'footprint size (nt)', range_column)
	df_filtered = df[(df['footprint size (nt)'] >= smallsize) & (df['footprint size (nt)'] <= largesize)] #select rows with desired footprint sizes only
	df_filtered.to_csv(outfile_path+"_3Dmeta_end5.csv", index=False)

	matrix3 = np.array(matrix3)        
	matrix3 = matrix3 * norm_number
	outfile3 = matrix3
	df3 = pd.DataFrame(outfile3)
	df3.columns = (list(range(-window_left,window_right+1)))
	df3.insert(0, 'footprint size (nt)', range_column)
	df_filtered3 = df3[(df3['footprint size (nt)'] >= smallsize) & (df3['footprint size (nt)'] <= largesize)] #select rows with desired footprint sizes only
	df_filtered3.to_csv(outfile_path+"_3Dmeta_end3.csv", index=False)

	# Collapse metagenes into another csv file - 2 columns 5' and 3' 1D metagenes.
	writerfile=open(outfile_path+"_1Dmetas.csv","w")
	writer = csv.writer(writerfile)
	meta_1D_5 = list(np.sum(df_filtered, axis=0))[1:]	# Skip 1st entry since that's a header.
	meta_1D_3 = list(np.sum(df_filtered3, axis=0))[1:]	# Skip 1st entry since that's a header.
	writer.writerow(["end_5","end3"])	# Header row.
	for position in range(len(meta_1D_5)):
		writer.writerow([meta_1D_5[position],meta_1D_3[position]])
	writerfile.close()


# For running from the command line, the code below pulls in the variables and calls main.
if __name__ == "__main__":	
	if len(sys.argv)!=10:
		print("Wrong number of inputs.")
		exit()
	main(sys.argv[1],sys.argv[2],sys.argv[3],sys.argv[4],sys.argv[5],sys.argv[6],sys.argv[7],sys.argv[8],sys.argv[9])